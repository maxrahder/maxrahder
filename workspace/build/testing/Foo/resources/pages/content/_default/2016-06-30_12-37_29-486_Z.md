#Introduction

In the last lab you set up a workspace-level test scenario named `unit`, that
contains the test file `MySuite.js`.

In this lab you'll add a few more tests to the workspace in order to 
see how Sencha Studio's details panel reports test results.

#Steps



??Add another expectation

Edit `test/unit/MySuite.js` and add a second expectation.

<pre class="runnable readonly 200">
describe("MySuite.js", function() {
    
    it("should pass", function() {
        expect(1).toBe(1);
        expect('hi').toBeTruthy();
    });

    
});</pre>

Run the test and Studio reports "1 passed", but if you click on the test itself, you'll see details
on the two expectations.

<img src="resources/images/senchatest/OnePassTwoExpects.png">


??Have one of the expectations fail

Edit `test/unit/MySuite.js` and change the second expectation to fail.

<pre class="runnable readonly 200">
describe("MySuite.js", function() {
    
    it("should pass", function() {
        expect(1).toBe(1);
        expect('hi').toBeFalsy();
    });

    
});</pre>

Run the test and Studio reports "1 failed", but if you click on the test itself, you'll see that
one expectation passed, and one failed. In other words, a spec is considered to have failed if any
expectation within it fails. 

??Add a second spec

Add another spec

<pre class="runnable readonly 260">
describe("MySuite.js", function() {
    
    it("should pass", function() {
        expect(1).toBe(1);
        expect('hi').toBeFalsy();
    });
    
    it("should test other things", function() {
        expect(1).toBe(1);
    });
    
});</pre>

Run the test and you should see "1 passed; 1 failed".


??What if no expectations are run?

Remove the expectation from the second spec:

<pre class="runnable readonly 260">
describe("MySuite.js", function() {
    
    it("should pass", function() {
        expect(1).toBe(1);
        expect('hi').toBeFalsy();
    });
    
    it("should test other things", function() {

    });
    
});</pre>

Then run the test. This time you should still see "1 passed; 1 failed" but, if you 
click on the results of the passing spec, you won't see any details &mdash; the details pane only
shows the actual results of expectations (or timeouts, which we'll talk about later).

<img src="resources/images/senchatest/NoExpectation.png">

Specs only fail if an +expect+ fails, or if the spec times out. It's valid to write 
a spec that has no +expect+. An example of this is using asynchronous tests that
wait for UI components to exist &mdash; such tests may time out (and fail), and have no need for an +expect()+ statement. You'll cover async later in class.

Correct the passing spec so that it also passes.

<pre class="runnable readonly 200">
describe("MySuite.js", function() {
    
    it("should pass", function() {
        expect(1).toBe(1);
        expect('hi').toBeTruthy();
    });

    it("should test other things", function() {

    });
    
});</pre>

??Run a single spec

Sencha Studio lets you run a single file or spec. Look in the `Run` pane and 
you'll see the scenario's files and the specs within them. There's a check box
to the left of each item &mdash; you can click on one to run an individual suite or spec.

Try it. Select the *should test other things* spec and run it. You'll see "1 passed"
because the other spec wasn't run. 

<img src="resources/images/senchatest/RunIndividualSpec.png"/>


??Add a scenario

One use-case for tests at the workspace level is to run tests against external applications or libraries.
For example, assume you're thinking of using the MathJS library, and want to verify that it
works the way you expect.

You can specify additional libraries to be loaded as the scenario is run, so, to test MathJS, create a new scenario. Select `Workspace > Tests`, 
then click the `Add` button in the scenarios section (on the right).

Name the scenario `MathJS` and set the directory to `MathJS`. Set the test type as In-browser before saving your changes.

<img src="resources/images/senchatest/AddMathJsTestScenario.png"/>

??Add a library

The MathJS library is at `https://cdnjs.cloudflare.com/ajax/libs/mathjs/3.2.1/math.min.js`.

Continue editing the `MathJS` scenario and, at the lower-right, choose `Add Library` and enter the
URL for MathJS.

<img src="resources/images/senchatest/SetMathJsLibrary.png"/>

??Add a Jasmine test

One thing you want to test is how MathJS addresses the issue of rounding errors in IEEE floating 
point numbers. If you're like most programmers, you probably lose sleep over things like this:

    alert((0.1 + 0.2) === 0.3); // False! o_O

You're going to set up a unit test to make sure MathJS handles that. 

Right-click on the new `MathJS` scenario, choose `New > Jasmine Test Suite` and name it `Equals.js`. Then, in the navigation tree, 
click on `Equals.js` and replace the default test code with:

<pre class="runnable readonly 300">
describe("Equals.js", function() {
    it("should handle floating point goofiness", function() {

        var sum, equals;
        
        // This bad floating point behavior is what we want to avoid.
        sum = (0.1 + 0.2);
        equals = (sum === 0.3); // Not equal, according to JavaScript IEEE 754
        expect(equals).toEqual(false);

        // The math library helps fix that.
        sum = math.add(0.1, 0.2);
        equals = math.equal(sum, 0.3);
        expect(equals).toEqual(true);

    });
});</pre>



Run the test and it should pass. Maybe that MathJS is worth looking into! <tt>:-)</tt>


<img src="resources/images/senchatest/TestMathJS.png"/ width="2000">
